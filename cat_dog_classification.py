# -*- coding: utf-8 -*-
"""cat dog classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TsmBjotDbFrdBVnR6QNrXbvn5ObNZ7Gr
"""

import os

dataset_path = '/content/drive/MyDrive/computer_vision'

from google.colab import drive
drive.mount('/content/drive')

num_cat_images = len(os.listdir(os.path.join(dataset_path, 'cat')))
num_dog_images = len(os.listdir(os.path.join(dataset_path, 'dog')))

print("Number of cat images:", num_cat_images)
print("Number of dog images:", num_dog_images)

import seaborn as sns
import matplotlib.pyplot as plt

labels = ['Cat', 'Dog']
counts = [num_cat_images, num_dog_images]

plt.figure(figsize=(10, 6))
sns.barplot(x=labels, y=counts)
plt.xlabel('Image Type')
plt.ylabel('Count')
plt.title('Number of Cat, Dog Images')
plt.show()

plt.figure(figsize=(10, 10))
sns.set_palette("Set3")
plt.pie(counts, labels=labels, autopct='%1.1f%%')
plt.title('Distribution of Cat, Dog Images')
plt.show()

import plotly.express as px

fig = px.bar(x=labels, y=counts)
fig.update_layout(
    xaxis_title='Image Type',
    yaxis_title='Count',
    title='Number of Cat, Dog Images',
    width=600,
    height=400
)
fig.show()

import plotly.graph_objects as go

fig = go.Figure(data=[go.Pie(labels=labels, values=counts, textinfo='percent',
                             insidetextorientation='radial')])
fig.update_layout(
    title='Distribution of Cat, Dog Images',
    width=800,
    height=500
)
fig.show()

cat_path = os.path.join(dataset_path, 'cat')
dog_path = os.path.join(dataset_path, 'dog')

cat_files = os.listdir(cat_path)

import cv2

fig, axes = plt.subplots(3, 3, figsize=(10, 10))
fig.suptitle('Cat Images', fontsize=16)
axes = axes.ravel() # This line reshapes the 3x3 array of axes into a 1D array, making it easier to iterate over the subplots.

for i, image_file in enumerate(cat_files[:9]):
    image_path = os.path.join(cat_path, image_file)
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    axes[i].imshow(image)
    axes[i].axis('off')

plt.tight_layout()
plt.show()

dog_files = os.listdir(dog_path)

fig, axes = plt.subplots(3, 3, figsize=(10, 10))
fig.suptitle('Dog Images', fontsize=16)
axes = axes.ravel()

for i, image_file in enumerate(dog_files[:9]):
    image_path = os.path.join(dog_path, image_file)
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    axes[i].imshow(image)
    axes[i].axis('off')

plt.tight_layout()
plt.show()

def load_and_preprocess_images(image_folder):
    image_files = os.listdir(image_folder)
    images = []
    for image_file in image_files:
        image_path = os.path.join(image_folder, image_file)
        image = cv2.imread(image_path)
        if image is not None:
            image = cv2.resize(image, (256, 256))
            images.append(image)
    return images

cat_files = load_and_preprocess_images(os.path.join(dataset_path, 'cat'))
dog_files = load_and_preprocess_images(os.path.join(dataset_path, 'dog'))

import numpy as np

cat_files = np.array(cat_files).reshape(-1, 256, 256, 3)
dog_files = np.array(dog_files).reshape(-1, 256, 256, 3)

"""cat_files and dog_files are presumably lists or arrays containing image data.

np.array(cat_files) and np.array(dog_files) are used to convert these lists/arrays into NumPy arrays.

.reshape(-1, 256, 256, 3) is used to reshape these arrays into a 4D format with the following dimensions:

-1: This is a placeholder for an unknown dimension. The use of -1 here means that NumPy will automatically calculate the size of this dimension based on the total number of elements in the array. In this context, it's often used to reshape a 1D or 2D array into a higher-dimensional array while maintaining the total number of elements.

256: This represents the height dimension of the images, setting it to 256 pixels.

256: This represents the width dimension of the images, also set to 256 pixels.

3: This represents the number of color channels in the images. It's typically 3 for RGB color images (red, green, blue).

So, when you execute these lines of code, cat_files and dog_files are reshaped into 4D arrays where each element corresponds to an image with dimensions 256x256 pixels and 3 color channels (RGB). The use of -1 in the first dimension ensures that the total number of elements remains the same as in the original arrays, and the dimensions are adjusted accordingly.
"""

all_files = np.concatenate((cat_files, dog_files), axis=0)

all_labels = np.concatenate((
    np.zeros(len(cat_files)),
    np.ones(len(dog_files)),
))

all_files_flat = all_files.reshape(-1, all_files.shape[1] * all_files.shape[2] * all_files.shape[3])

"""
The code you provided is reshaping a 4D NumPy array called all_files into a 2D array called all_files_flat. Let me explain what this code does step by step:

all_files is a 4D NumPy array, typically representing a collection of images. The dimensions of this array are as follows:

The first dimension represents the number of images (the "batch size").
The second dimension represents the height of each image.
The third dimension represents the width of each image.
The fourth dimension represents the number of color channels in each image (e.g., 3 for RGB images).
all_files.shape[1] * all_files.shape[2] * all_files.shape[3] calculates the total number of elements in each image. This is done by multiplying the dimensions of height, width, and color channels. Essentially, it computes the size of a flattened version of each image.

reshape(-1, all_files.shape[1] * all_files.shape[2] * all_files.shape[3]) reshapes the 4D array all_files into a 2D array called all_files_flat. The -1 in the first dimension indicates that NumPy should calculate the size of this dimension based on the total number of elements in the original array. The second dimension is set to the size of each flattened image."""

cat_files_new = all_files_flat[all_labels == 0].reshape(-1, 256, 256, 3)
dog_files_new = all_files_flat[all_labels == 1].reshape(-1, 256, 256, 3)

print("Resampled cat files shape:", cat_files_new.shape)
print("Resampled dog files shape:", dog_files_new.shape)

"""all_labels is assumed to be a 1D NumPy array or list containing labels for each of the images in all_files_flat. For example, 0 might represent cats, and 1 might represent dogs.

all_files_flat is a 2D NumPy array where each row represents a flattened version of an image.

all_labels == 0 is a boolean condition that checks which elements in all_labels are equal to 0. This results in a boolean mask with True where the condition is met (cat labels) and False elsewhere.

all_files_flat[all_labels == 0] uses the boolean mask to select rows from all_files_flat where the corresponding label is 0. This effectively filters out the rows corresponding to cat images.

.reshape(-1, 256, 256, 3) reshapes the filtered data into a 4D array, where -1 in the first dimension is used to calculate the size of this dimension based on the remaining dimensions. The dimensions (256, 256, 3) specify the desired shape of each image (height, width, color channels).
"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

cat_files_new = cat_files_new.astype('float32') / 255.0
dog_files_new = dog_files_new.astype('float32') / 255.0

image_shape = (256,256)

X = np.concatenate((cat_files_new, dog_files_new))
y = np.concatenate(([0]*349, [1]*373))

X_resized = np.array([cv2.resize(image, image_shape) for image in X])
X_flattened = X_resized.reshape(X_resized.shape[0], -1)

X_train, X_test, y_train, y_test = train_test_split(X_flattened, y,
                                                    test_size=0.2,
                                                    stratify = y,
                                                    random_state=42)

svm_model = SVC()
svm_model.fit(X_train, y_train)

y_pred = svm_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

f1 = f1_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
classification_rep = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print("F1 Score:", f1)
print("Precision:", precision)
print("Recall:", recall)
print("Classification Report:\n", classification_rep)
print("Confusion Matrix:\n", conf_matrix)

dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

y_pred = dt_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

f1 = f1_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
classification_rep = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print("F1 Score:", f1)
print("Precision:", precision)
print("Recall:", recall)
print("Classification Report:\n", classification_rep)
print("Confusion Matrix:\n", conf_matrix)

rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

f1 = f1_score(y_test, y_pred, average='weighted')
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
classification_rep = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print("F1 Score:", f1)
print("Precision:", precision)
print("Recall:", recall)
print("Classification Report:\n", classification_rep)
print("Confusion Matrix:\n", conf_matrix)

from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

model = Sequential()

model.add(Conv2D(32, (3, 3),
                 activation='relu',
                 kernel_initializer='he_uniform',
                 padding='same', input_shape=(150, 150, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu',
                 kernel_initializer='he_uniform', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform',
                 padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128,activation='relu',kernel_initializer='he_uniform'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer=SGD(lr=0.01),loss='binary_crossentropy',
              metrics=['accuracy'])

full_datagen = ImageDataGenerator(
    rescale=1.0/255.0,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True
)

full_data = full_datagen.flow_from_directory(
    '/content/drive/MyDrive/computer_vision',
    class_mode='binary',
    batch_size=64,
    target_size=(150, 150)
)

history = model.fit_generator(
    full_data,
    steps_per_epoch=len(full_data),
    validation_data=full_data,
    validation_steps=len(full_data),
    epochs = 20
)

model.save('cats-vs-dogs.h5')

train_loss, train_accuracy = model.evaluate(full_data, steps=len(full_data))
print("Training Accuracy:", train_accuracy)

training_loss = history.history['loss']
training_accuracy = history.history['accuracy']
validation_loss = history.history['val_loss']
validation_accuracy = history.history['val_accuracy']
epochs = range(1, len(training_loss) + 1)

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs, training_loss, 'bo', label='Training Loss')
plt.plot(epochs, validation_loss, 'r', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, training_accuracy, 'bo', label='Training Accuracy')
plt.plot(epochs, validation_accuracy, 'r', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

